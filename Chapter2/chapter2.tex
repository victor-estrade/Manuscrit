%!TEX root = ../thesis.tex
%*******************************************************************************
%********************************** Second Chapter *****************************
%*******************************************************************************

\chapter{SOTA}  %Title of the First Chapter
\label{chap:sota}

\ifpdf
    \graphicspath{{Chapter2/Figs/Raster/}{Chapter2/Figs/PDF/}{Chapter2/Figs/}}
\else
    \graphicspath{{Chapter2/Figs/Vector/}{Chapter2/Figs/}}
\fi

\section{Unsuitable methods} % (fold)
\label{sec:unsuitable_methods}

\topic{Variational inference requires likelihood and ABC do not scale.}
\content{What we are not going to devellop. But justifying why !}

\subsection{ABC methods} % (fold)
\label{sub:abc_methods}

\content{short review of ABC methods and why we cannot rely on it for this problem.}

\victor{TODO : Décrire succintement rejection algo et les idées principales d'amélioration. }

One solution to do inference with an intractable likelihood is the Approximate Bayesian Computation (ABC).
The most traditional ABC algorithm is the rejection algorithm which is computationally expensive.
Although significant improvement can be achieved with advanced Monte Carlo methods this is still known to take a long time to converge \needcite.


\subsection{Variational inference} % (fold)
\label{sub:variational_inference}

\topic{Variational inference requires likelihood}

\victor{TODO : VI avec des NN. Stochastic VI.}
On the other hand Variational Inference (VI) is extremely fast but can lead to biased estimation which is a severe drawback when it leads to underestimating the uncertainty.

In high Energy Physics (HEP), which motivated this work, the use of machine learning produced summary statistics combined with domain knowledge allow to conduct exact inference in the absence of nuisance parameters.
\victor{"Extact" inference me semble maladroit}


\subsection{Bayesian networks} % (fold)
\label{sub:bayesian_networks}

\topic{Could be a solution. But no time to explore everything}
\content{En vrai les Bayesian networks }
\victor{Other physicists have tried and got prelimnary results. Need to see if they made progress !}


\section{Domain adaptation} % (fold)
\label{sec:domain_adaptation}

\topic{If the classifier output is independant of the nuisance parameters then we win !}

\subsection{Continuous domain adaptation} % (fold)
\label{sub:continuous_domain_adaptation}

\topic{This is a very peculiar case of domain adaptation}
\content{We have a continuous domain shift. Not a discreat number of domains. + we are supervised}

\subsection{Data augmentation} % (fold)
\label{sub:data_augmentation}

\topic{The easiest (and naive) way of being good across domain}

\subsection{Adversarial training} % (fold)
\label{sub:adversarial_training}

\content{DANN and Pivot}
\content{Make clear that Pivot is better founded (theory) than DANN, the bottleneck at the end is a good idea (says Maths)}


\subsection{Cross-entropy} % (fold)
\label{sub:cross_entropy}

\topic{Is the cross-entropy the right objective function ?}
Recall that the optimality of the Bayesian classifier is no more.
Let's not stay stuck on this.


\section{Soft histograms} % (fold)
\label{sec:soft_histograms}

\topic{Only histograms prevent the entire pipeline to be differentiable. Fix it and you win !}

\content{INFERNO and other soft histograms + Inferted Fisher info matrix as objective function}


\subsection{Differentiable histograms} % (fold)
\label{sub:differentiable_histograms}

\topic{Using softmax or gaussian gradients the histograms becomes differentiable}

\subsection{Differentiable simulator} % (fold)
\label{sub:differentiable_simulator}

\topic{It is possible to make the simulator sufficiently differentiable according to the nuisance parameters}

\content{Fast simulation through recomputing only the skewed features according to nuisance parameter}

\subsection{Limitations} % (fold)
\label{sub:limitations}

% subsection limitations (end)
\topic{INFERNO is a good way of takling systematics (if you can make siluation differentiable enough and invert the fisher info matrix)}


\section{Mining gold} % (fold)
\label{sec:mining_gold}

\topic{Improve the simulator to give more informations about the intractable likelihood !}

\content{Je sais pas trop encore quoi mettre là dedans....}


