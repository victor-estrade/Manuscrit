%!TEX root = ../thesis.tex
%*******************************************************************************
%****************************** Third Chapter **********************************
%*******************************************************************************

\chapter{Applications to HEP}
\label{chap:applications}
% **************************** Define Graphics Path **************************
\ifpdf
    \graphicspath{{Chapter5/Figs/Raster/}{Chapter5/Figs/PDF/}{Chapter5/Figs/}}
\else
    \graphicspath{{Chapter5/Figs/Vector/}{Chapter5/Figs/}}
\fi

\topic{Density networks is a powerful way to solve the inverse problem while taking into account the uncertainties and nuisance parameters.}

\cecile{This is a example of comment}

\victor{This is a example of comment}

\section{Introduction}

\topic{Solving the inverse problem is hard. Taking into account the uncertainties is crucial.}

Data science is now a standard in the toolbox of experimental scientists.
Especially machine learning that is often used to reduce dimensionality while keeping relevant information.
Among the challenges that receive special attention lies the \emph{inverse problem}.

This challenge occurs notably in simulation based experimental science which includes for example nuclear physics, evolutionary biology and sociology.
Most of the time simulations are only working in \emph{forward mode}.
Meaning that it is only possible to go from the causal parameters to the observations but not the other way around.
This is often the result of an intractable likelihood due to high dimensional integrals.
The \emph{inverse problem} gather all the methods to extract the unobserved causal parameters from the measured data.

In addition scientists often have to cope with biases and uncertainties.
The final result of analysis is typically presented as : $\text{parameter} = \text{value} \pm \text{uncertainty}$.
A method that allow to trace back the causal parameters from observations must come with its prescription to compute the uncertainties of the predictions.

In some cases not all of the causal parameters are interesting for the study.
Causal parameters are split into two categories : the \emph{parameters of interest} which are the objective of the study and the \emph{nuisance parameters} which often came from apparatus response and/or uncontrolled environment.

In this work is proposed a method to tackle the inverse problem when simulation is available while computing the uncertainty on the inferred causal parameters and taking into account nuisance parameters.


\section{Related work}

\topic{This method is inspired from mixture density networks, inferno and neural statistician. 
Other solutions to the inverse problem includes ABC, VI and probabilistic programming.}

\victor{Add citations}

\victor{Cette section contient un peu de fourre tout pour me souvenir des sujets à aborder dans la partie sur l'état de l'art}

\victor{Développer plus ? Décrire rejection algo et les idées principales d'amélioration. }

One solution to do inference with an intractable likelihood is the Approximate Bayesian Computation (ABC).
The most traditional ABC algorithm is the rejection algorithm which is computationally expensive.
Although significant improvement can be achieved with advanced Monte Carlo methods this is still known to take a long time to converge.

\victor{Développer plus ? VI avec des NN. Stochastic VI.}
On the other hand Variational Inference (VI) is extremely fast but can lead to biased estimation which is a severe drawback when it leads to underestimating the uncertainty.

In high Energy Physics (HEP), which motivated this work, the use of machine learning produced summary statistics combined with domain knowledge allow to conduct exact inference in the absence of nuisance parameters.
\victor{"Extact" inference me semble maladroit}

\victor{Another improvement is Mining gold. Or Also Bayesian networks ...}

Causal parameters are often related to properties of the distribution of the data in statistical simulations.
The architecture should reflect this link in order for a neural network to capture the relevant information.
This work is using Mixture density network \cite{Bishop94mixturedensity} combined with neural network architectures that allow to take a set of real valued vectors as input.
Such architecture is shown in \cite{Edwards17neuralstatistician}, in the context of transfer learning and one shot learning, where the neural network is producing summary statistics to embed the link between similar datasets.
\cite{DECASTRO2019170inferno} is the closest work of this study in which the authors optimize a neural network to produce of summary statistics that reduces the uncertainty on the parameters of interest estimation.


\section{Direct regression}

\topic{A simple but efficient solution is to map the input data to the target with a neural network whose architecture and training procedure are carefully chosen.}

\subsection{Setting}
\topic{Although the generator is available Bayesian inference is difficult because of the intractable likelihood.}

A generative model $G(\theta)$ is available to simulate the studied process and retrieve the observations $x$ from given parameters $\theta$.
The objective is to reverse the generator $G^{-1}(x)$ to access the quantities of interest ruling the process.

Since the process is stochastic the generator can produce different observations from the same parameters.
The probability of observing $x$ if the generator is fed with $\theta$ is $p(x | \theta)$.
Therefore reversing the generator means finding $p(\theta | x)$.
From Bayes theorem we get :

\begin{equation}
    p(\theta | x) = \frac{p(x | \theta) p(\theta) }{p(x)}
\end{equation}
Unfortunately the likelihood $p(x | \theta)$ is often intractable because of high dimensional integrals.
To avoid this pitfall the posterior $p(\theta | x)$ is approximated by a tractable distribution $q_\phi(\theta | x)$.


\subsection{Density network}

\topic{Mixture density networks are a tractable but powerful tool to approximate a conditional probability density.}

A way of approximating the posterior $p(\theta | x)$ is to define a tractable but flexible enough family of distribution $q_\phi(\theta | x)$ parametrized by $\phi$.

Initially introduced in \cite{Bishop94mixturedensity} as a generalization of least square methods to train neural network, the mixture density networks (MDN) can be made as powerful as one require while staying tractable and allowing to estimate the uncertainties of the predictions.

The objective density is approximated by a linear combination of kernels $k$ :

\begin{equation}
    q_\phi(\theta | x) = \sum_{i=0}^K m_i(x ; \phi) k_i(\theta | x ; \phi)
\end{equation}
where $m_i(x ; \phi)$ are the mixture coefficient
and the kernels $k_i(\theta | x ; \phi)$ usually taken as Gaussian :
\begin{equation}
    k_i(\theta | x ; \phi) = \frac{1}{\sigma_i(x ; \phi) \sqrt{2 \pi}} e^{- \frac{1}{2} \left ( \frac{\theta-y_i(x ; \phi)}{\sigma_i(x ; \phi)} \right )^2} 
\end{equation}

$m_i(x ; \phi)$, $\sigma_i(x ; \phi)$ and $y_i(x ; \phi)$ are the outputs of a neural network, whose parameters are gathered in $\phi$, and taking the data as input.
Finally, the mixture coefficient have to sum up to 1.
\begin{equation}
    \sum_{i=0}^K m_i(x ; \phi) =  1
\end{equation}

The motivation for this approximation is twofold.
First, given enough well chosen parameters a Gaussian mixture model can approximate any density.
Second, a neural network with enough hidden unit is able to approximate any continuous function with arbitrarily precision.
Combining these two properties leads to an arbitrarily powerful approximation of any conditional density $p(\theta|x)$ given enough resources.

The neural network parameters $\phi$ can then be obtained by maximizing the likelihood that the model produced the given data.

\begin{equation}
    \phi^\star = \argmax_\phi \mathcal L (\phi)
\end{equation}
\begin{equation}
    \mathcal L (\phi) = \sum_{i=0}^K m_i(x ; \phi) k_i(\theta | x ; \phi)
\end{equation}

Similarly to training a regular neural network regressor with least square, MDN's training is supervised therefore requires data for which the ground truth is available which is verified in our case.

Finally the likelihood, with Gaussian kernels, is fully differentiable making possible the use of stochastic gradient descent methods to obtain the neural network parameters $\phi$.

\subsection{Training}

\topic{MDN are trained like classical regressor and allow to compute the uncertainty of the predictions.}

The parameters $\phi$ are obtained by maximizing the likelihood :
\begin{equation}
    \phi^\star = \argmax_\phi \mathcal L (\phi)
\end{equation}
For convenience the optimization is usually turned into a minimization of the negative log likelihood (NLL) :
\begin{equation}
    \phi^\star = \argmin_\phi - \log \mathcal L (\phi)
\end{equation}

In the simple case of one Gaussian component ($K=1$) the NLL is :
\begin{equation}
    \phi^\star = \argmin_\phi \left\{ \log(\sigma(x;\phi)) + \frac{1}{2}\log(2\pi) + \frac{(\theta - y(x;\phi))^2}{2\sigma(x;\phi)^2} \right\}
\end{equation}

The learning procedure is supervised since we need both observed data $x$ and the associated value for  $\theta$.

Since the likelihood is fully differentiable in $\phi$, the optimization can be solved using stochastic gradient descent methods.

\begin{algorithm}[H]
 \For{$i \in [0, N]$}{
  $\theta_i$    $\gets$ sample from $p(\theta)$ \;
  $x_i$      $\gets$ $G(\theta_i)$ \;
  $m_i, y_i, \sigma_i$ $\gets$ $f(x_i; \phi_i)$ \;
  $loss_i$   $\gets$ $-\log \mathcal L(\phi_i; m_i, y_i, \sigma_i)$ \;
  $grads_i$  $\gets$ backward($loss_i$) \;
  $\phi_{i+1}$ $\gets$ Optimizer($\phi_i$, $grads_i$) \;
 }
 \caption{Training procedure}
\end{algorithm}

As long as a flexible and powerful enough parametric differentiable function is mapping the data $x$ to the parameter $\theta$ it is possible to approximate the conditional density.
Once trained the inference is straightforward.
From the experimental data $x^\star$ the mean and variance can be easily extracted:

\begin{align}
    \bar \theta & = \mathbb E_{p(\theta | x^\star)}[\theta] \\
    & \approx \mathbb E_{q_\phi(\theta | x^\star)}[\theta] \\
    & = \sum_{i=0}^K m_i(x^\star ; \phi) \int d\theta ~ \theta ~ k_i(\theta | x^\star ; \phi) \\
    & = \sum_{i=0}^K m_i(x^\star ; \phi) y_i(x^\star ; \phi)
\end{align}

\begin{align}
    \Delta\theta^2 & = \mathbb V_{p(\theta | x^\star)}[\theta] \\
    & \approx \mathbb V_{q_\phi(\theta | x^\star)}[\theta] \\
    & = \sum_{i=0}^K m_i(x^\star ; \phi) \int d\theta ~ \theta^2 ~ k_i(\theta | x^\star ; \phi) - \bar \theta^2 \\
    & = \sum_{i=0}^K m_i(x^\star ; \phi) \left [ \sigma_i(x^\star ; \phi)^2 + y_i(x^\star ; \phi)^2 - \bar \theta^2 \right ]
\end{align}

\subsection{Neural network architecture}
\topic{Details about the neural network architecture for MDN with importance weighted dataset as input}

In order to accurately capture the complex mapping between the data and the parameters the architecture of the neural network should embody the constraints of the chosen family distribution.

The requirement that the mixture coefficients $m_i$ sum up to 1 is enforced using softmax operator on the $K$ output neurons representing the $m_i$.
Similarly the standard deviation of Gaussians should always be strictly positive which is fulfilled by interpreting the neuron output as $\log(\sigma_i)$.
No particular operation are necessary on the mean $y_i$ of the Gaussians since it can take whatever real value.

If the studied process is stochastic the observations are usually composed of repeated independent measurements of an event.
Then the observable is not a real valued vector $x \in \RR$ but a set of data points $D = \{v_i \in \RR \}_{i=0}^N$.
The output is still a real valued vector meaning that the neural network architecture should include some reduction function.
Such function are usually averages, minima, maxima, products, sums, geometric means or others that reduces the dimension and remain invariant to the input order of the vectors.
In practice the average is chosen.

When the studied process includes some very rare events the simulation uses importance sampling. 
The simulation output includes importance weights to allow many rare events to be produced while keeping the distribution of events similar to reality.
The neural network must to take into account the importance weights to accurately regress the parameters.
Which leads to use weighted average instead of simple average.

More precisely, for 2 datasets $D$ and $D^\prime$ if the associated empirical distribution are equal then the neural network output should be also equal.

\begin{equation}
    \forall x, p_D(x) = p_{D^\prime}(x) \implies f(D; \phi) = f(D^\prime; \phi)
\end{equation}

with,
\begin{equation}
    p_D(x) = \sum_{v \in D} w_i \delta (x - v)
\end{equation}
and $\delta$ is the Dirac distribution function.


\subsection{Nuisance parameters}
\topic{Nuisance parameters are marginalized using Monte Carlo integral approximation.}

The objective is to infer the parameter $\mu$ of a model that describes a stochastic system from experimental data $D$.
However $\mu$ alone is not enough to describe the experimental data.
More causal parameters, noted $\alpha$, are required.
Since the parameters $\alpha$ are not the object of study they are tagged as \emph{nuisance} parameters in opposition to the parameter \emph{of interest} $\mu$.

The nuisance parameters have to be marginalized.
\begin{equation}
    p(\mu | x) = \int d\alpha ~ p(\alpha | x) ~ p(\mu | x, \alpha)
\end{equation}

This integral can be approximated with Monte Carlo.

\begin{equation}
	\int d\alpha ~ p(\alpha) ~ f(\alpha)
	\approx \sum_i w_i ~ f(\alpha_i)
\end{equation}

Where $p(\mu | x, \alpha)$ is approximated using a trained MDN as seen previously.
The neural network $f$ produces the mixture parameters $m_i, y_i, \sigma_i$ from the experimental data $x^\star$ and sampled $\alpha$.

\begin{algorithm}[H]
 \For{$i \in [0, N]$}{
  $\alpha_i, w_i$ $\gets$ MC sample from $p(\alpha)$ \;
  $m_j, y_j, \sigma_j = f(x^\star, \alpha; \phi)$
  $\bar\mu = \sum_{j=0}^K m_j y_j $ \;
  $\Delta\mu = \sum_{j=0}^K m_j \left [ \sigma_j^2 + y_j^2 - \bar \mu^2 \right ]$ \;
  $\hat\mu$  $\gets$ $\hat\mu + w_i \times \bar\mu$ \;
  $\hat\sigma$  $\gets$ $\hat\sigma + w_i \times (\bar\mu^2 + \Delta\mu^2)$ \;
 }
$\hat\sigma$  $\gets$ $\hat\sigma - \hat\mu^2$ \;
\caption{Marginalizing the nuisance parameters $\alpha$ using MC to compute the integral.}
\end{algorithm}


\subsection{Discussing the related work} 

\begin{itemize}
    \item related to Amortized VI ? Related to simple Gaussian fit ?
\end{itemize}


\section{Experiments}

Note : we do not need a mixture of Gaussian ($K=1$).


\subsection{The example} 
\subsubsection{General case} 

About the separation between nuisance parameters and parameters of interest

\subsubsection{A case study in Physics} 

About higgs, Poisson, etc.


\subsection{Synthetic data}

\subsection{Real data}





%============================================================================================================
% SOTA REVIEW
%============================================================================================================


\chapter{Review of the state of the art}

Found this paper \url{https://arxiv.org/pdf/1903.10563.pdf} which review ML + Physics.

So let's dive into the state of the art of inference in Physics using ML.
Especially in the inverse problem setting.

\section{Table of content}

To help surfing in this document let's start with summarizing the approaches and give pointers to the relevant sections.


\subsection{ ABC }

Approximate Bayesian Computation is ...


\subsection{ Domain adaptation }

Pivot and other possibilities...


\subsection{ Mining gold }

Augment the simulated data with the likelihood ratio ...


\subsection{ TODO Papers }

\begin{itemize}
    \item \url{https://arxiv.org/abs/1903.01473} : Nuisance hardened data compression for fast likelihood-free inference
    \item \url{https://arxiv.org/abs/1707.07113} : Adversarial Variational Optimization of Non-Differentiable Simulators
    \item \url{https://arxiv.org/abs/1806.11484} : Deep Learning and its Application to LHC Physics
    \item \url{https://arxiv.org/abs/1611.01046} : Learning to Pivot with Adversarial Networks
    \item \url{https://arxiv.org/abs/1706.04008} : Recurrent Inference Machines for Solving Inverse Problems
    \item \url{https://arxiv.org/abs/1506.02169} : Approximating Likelihood Ratios with Calibrated Discriminative Classifiers
    \item \url{https://arxiv.org/abs/1007.1727} : Asymptotic formulae for likelihood-based tests of new physics
    \item \url{https://arxiv.org/abs/1805.07226} : Sequential Neural Likelihood: Fast Likelihood-free Inference with Autoregressive Flows
    \item \url{https://arxiv.org/abs/1805.00020} : A Guide to Constraining Effective Field Theories with Machine Learning
    \item \url{https://arxiv.org/abs/1805.00013} : Constraining Effective Field Theories with Machine Learning
    \item \url{https://arxiv.org/abs/1805.12244} : Mining gold from implicit models to improve likelihood-free inference
    \item \url{https://arxiv.org/abs/1610.08328} : Event generator tuning using Bayesian optimization
    \item \url{https://arxiv.org/abs/1801.01497} : Massive optimal data compression and density estimation for scalable, likelihood-free inference in cosmology
    \item \url{https://arxiv.org/abs/1802.03537} : Automatic physical inference with information maximising neural networks
    \item \url{https://www.pp.rhul.ac.uk/~cowan/stat/aachen/cowan_aachen14_1.pdf} : Cours de Glen 2012 part 1
    \item \url{https://www.pp.rhul.ac.uk/~cowan/stat/aachen/cowan_aachen14_2.pdf} : Cours de Glen 2012 part 2
    \item \url{https://www.pp.rhul.ac.uk/~cowan/stat/aachen/cowan_aachen14_3.pdf} : Cours de Glen 2012 part 3
    \item \url{https://www.pp.rhul.ac.uk/~cowan/stat/aachen/cowan_aachen14_4.pdf} : Cours de Glen 2012 part 4
    \item \url{https://www.pp.rhul.ac.uk/~cowan/stat/aachen/cowan_aachen14_5.pdf} : Cours de Glen 2012 part 5
    \item \url{} : 
    \item \url{https://cds.cern.ch/record/1099977/files/p111.pdf} : Computing Likelihood Functions for High-Energy Physics Experiments when Distributions are Defined by Simulators with Nuisance Parameters
    \item \url{} : 
    \item \url{} : 
    \item \url{} : 
    \item \url{} : 
    \item \url{} : 
\end{itemize}





