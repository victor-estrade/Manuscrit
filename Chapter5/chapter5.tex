%!TEX root = ../thesis.tex
%*******************************************************************************
%******************************  5th  Chapter **********************************
%*******************************************************************************

\chapter{Experimental results}
\label{chap:xp}
% **************************** Define Graphics Path **************************
\ifpdf
    \graphicspath{{Chapter5/Figs/Raster/}{Chapter5/Figs/PDF/}{Chapter5/Figs/}}
\else
    \graphicspath{{Chapter5/Figs/Vector/}{Chapter5/Figs/}}
\fi



\section{Toy d'isabelle} % (fold)
\label{sec:toy_d_isabelle}

MNIST les 1 vs les 0.
Projection 1D.
L'observable est le nombre de pixel alumé et la systematique est la luminosité.
Ça donne une observable affectée par la systématique.

Mais si l'observable est la rondeur le l'image alors on a une observable orthogonale à la systématique.



\section{Performances on toys} % (fold)
\label{sec:performances_on_toys}

\topic{On toy problems all methods achieve good or perfect inference}

A complex link bounds the observables $\xx$ and the parameters (nuisance and interest).
It is impossible to completely reduce the dependency between $y|x$ et $\alpha$.
Hence impossible to reduce the systematic uncertainty to zero.

Here methods are compared to the best possible inference.



\subsection{Performance according to sample size} % (fold)
\label{sub:performance_according_to_sample_size}



Performance en fonction du nombre d'events dans le dataset de test ?
Evolution de la variance stat et syst en fonction de N\_samples.


\begin{figure}[htb]
  \centering
  \begin{subfigure}[t]{0.49\linewidth}
    \includegraphics[width=\linewidth]{minitoy/marginal_y.png}
    \caption{$p(y|x)$}
    \label{fig:marginal_y}
  \end{subfigure}%
  \hfill
  \begin{subfigure}[t]{0.49\linewidth}
    \includegraphics[width=\linewidth]{minitoy/marginal_alpha.png}
    \caption{$p(\alpha|x)$}
    \label{fig:marginal_alpha}
  \end{subfigure}
  \caption{Posterior probabilities for $y$ (left) and $\alpha$ (right)}
  \label{fig:marginals}
\end{figure}

\emph{Remarque :}
L'erreur statistique et l'erreur systématique diminuent ensemble avec l'augmentation du nombre de donnée.
Plus on a de donnée meilleur est l'inférence sur $\alpha$.
Donc c'est normal !

Du coup j'ai vraiment du mal avec le concepte de l'erreur systématique qui ne diminue que doucement avec l'augmentation des données.

Si l'effet est invisible sur les données alors on a pas de problème.
Si l'effet est visible alors on peut contraindre + les paramètres de nuisance puisqu'on peut le mesurer !


\begin{figure}[htb]
  \centering
  \begin{subfigure}[t]{0.49\linewidth}
    \includegraphics[width=\linewidth]{s3d2/marginal_r.png}
    \caption{$p(r|x)$}
    \label{fig:marginal_r}
  \end{subfigure}%
  \hfill
  \begin{subfigure}[t]{0.49\linewidth}
    \includegraphics[width=\linewidth]{s3d2/marginal_lam.png}
    \caption{$p(\lambda|x)$}
    \label{fig:marginal_lambda}
  \end{subfigure}

  \begin{subfigure}[t]{0.49\linewidth}
    \includegraphics[width=\linewidth]{s3d2/marginal_mu.png}
    \caption{$p(\mu|x)$}
    \label{fig:marginal_mu}
  \end{subfigure}
  \caption{Posterior probabilities for $y$ (left) and $\alpha$ (right)}
  \label{fig:marginals}
\end{figure}









\subsection{Performances according to the number of nuisance parameters} % (fold)
\label{sub:performances_according_to_the_number_of_nuisance_parameters}

\content{Show how the nuisance parameters are degrading the performances}

Le nombre de param de nuisance n'est pas important. 
Mais l'intrication de l'influence des params de nuisance et du param d'intéret sur les observables l'est.









\subsection{Performances of robustness to systematic effect} % (fold)
\label{sub:performances_of_robustness_to_systematic_effect}


\content{Section specifique aux méthodes du chapitre 2}








\subsection{Calibration influence} % (fold)
\label{sub:calibration_influence}

Then the best way to reduce the systematic uncertainty is to improve calibration !








\section{Real data} % (fold)
\label{sec:real_data}


\victor{Find out why this is does not work : \url{https://arxiv.org/pdf/1909.03081.pdf} ??}
\victor{La simulation est trop précise. cf resultat sur l'impossibilité de séparer les domaines créé}








\subsection{Nothing beats the baseline} % (fold)
\label{sub:nothing_beats_the_baseline}

\content{Show results on Higgs}







\subsection{Impossible to separate between domains} % (fold)
\label{sub:impossible_to_separate_between_domains}

\content{Show results of classifier trying to separate events between "extreme" values of nuisance params}









\subsection{Results with or without calibration} % (fold)
\label{sub:results_with_or_without_calibration}

\content{Compare results with or without using the current data in the calibration}







\subsection{Too rare signals} % (fold)
\label{sub:too_rare_signals}


\content{Explain and show that the issue comes from the imbalance between signals and backgrounds}

The scatter plot properties is much more dependent to noise or nuisance parameters than to the parameter of interest.




\section{Forest robustness} % (fold)
\label{sec:forest_robustness}

\victor{Grad boost is robust because trees disagrees between themselves}


